{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking- we use access modifiers e.g += means match one or more The result is a grouping of the words in “chunks”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer # unsupervised sentence tokenizer but you can train it if you want.\n",
    "with open('Allheadlines.csv') as csvfile:\n",
    "    readCSV = csv.reader(csvfile)\n",
    "    for row in readCSV:\n",
    "        example_text = row[0]\n",
    "        All_lowercase = example_text.lower()\n",
    "        tokenized = word_tokenize(All_lowercase)\n",
    "        stop_words = set(stopwords.words(\"English\"))\n",
    "        filtered_sentence = [w for w in tokenized if not w in stop_words]\n",
    "        train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "        sample_text = state_union.raw(\"2006-GWBush.txt\")\n",
    "        custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "        tokenizedd = custom_sent_tokenizer.tokenize(sample_text)\n",
    "        def process_content():\n",
    "            try:\n",
    "                for i in filtered_sentence:\n",
    "                    words = nltk.word_tokenize(i)\n",
    "                    tagged = nltk.pos_tag(words)\n",
    "                    chunkGram = \"\"\" Chunk:{<RB.?>*<VB.?>*<NNP><NN>?} \"\"\"\n",
    "                    chunkParser = nltk.RegexpParser(chunkGram)\n",
    "                    chunked = chunkParser.parse(tagged)\n",
    "                    print(chunked)\n",
    "            except Exception as e:\n",
    "                    print(str(e))\n",
    "        process_content()\n",
    "        \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
